{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp, os\n",
    "import kfp.dsl as dsl \n",
    "import kfp.compiler as compiler\n",
    "import kubernetes.client.models as k8s\n",
    "from kfp.aws import use_aws_secret\n",
    "import namesgenerator\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMESPACE = os.environ.get(\"NAMESPACE\") \n",
    "\n",
    "kubeflow_address = f\"http://{NAMESPACE}.kubeflow.odsc.k8s.hydrosphere.io\"\n",
    "hydrosphere_address = f\"http://{NAMESPACE}.serving.odsc.k8s.hydrosphere.io\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(kubeflow_address)\n",
    "print(hydrosphere_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will obtain all training data for our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"hydrosphere\"\n",
    "version = \"v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"download\",\n",
    "        image=f\"{username}/mnist-pipeline-download:{version}\",\n",
    "        file_outputs={\"data_path\": \"/data_path.txt\"},\n",
    "        arguments=[\"--hydrosphere-address\", kwargs[\"hydrosphere_address\"]]\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(hydrosphere_address):\n",
    "    \n",
    "    # 01 Download Data\n",
    "    download = download_op(\n",
    "        hydrosphere_address=hydrosphere_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipelines client\n",
    "client = kfp.Client(kubeflow_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an experiment name\n",
    "experiment_name='MNIST Showreal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get or create an experiment_id\n",
    "try:\n",
    "    experiment_id = client.get_experiment(experiment_name=experiment_name).id\n",
    "except:\n",
    "    experiment_id = client.create_experiment(experiment_name).id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name modest_sammet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://fc13d681.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/d61c0549-86c5-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Train Model & Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will create a model and an autoencoder & train them on the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"train_model\",\n",
    "        image=f\"{username}/mnist-pipeline-train-model:{version}\",\n",
    "        file_outputs={\n",
    "            \"accuracy\": \"/accuracy.txt\",\n",
    "            \"model_path\": \"/model_path.txt\",\n",
    "            \"classes\": \"/classes.txt\",\n",
    "        },\n",
    "        arguments=[\n",
    "            \"--data-path\", kwargs[\"data_path\"],\n",
    "            \"--learning-rate\", kwargs[\"learning_rate\"],\n",
    "            \"--epochs\", kwargs[\"epochs\"],\n",
    "            \"--batch-size\", kwargs[\"batch_size\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"]\n",
    "        ],\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"train_autoencoder\",\n",
    "        image=f\"{username}/mnist-pipeline-train-autoencoder:{version}\",\n",
    "        file_outputs={\n",
    "            \"model_path\": \"/model_path.txt\",\n",
    "            \"loss\": \"/loss.txt\",\n",
    "            \"classes\": \"/classes.txt\",\n",
    "        },\n",
    "        arguments=[\n",
    "            \"--data-path\", kwargs[\"data_path\"], \n",
    "            \"--steps\", kwargs[\"steps\"], \n",
    "            \"--learning-rate\", kwargs[\"learning_rate\"],\n",
    "            \"--batch-size\", kwargs[\"batch_size\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"]\n",
    "        ]\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    hydrosphere_address,\n",
    "    model_learning_rate,\n",
    "    model_epochs,\n",
    "    model_batch_size,\n",
    "    autoencoder_learning_rate,\n",
    "    autoencoder_steps,\n",
    "    autoencoder_batch_size,\n",
    "):\n",
    "    # 01 Download Data\n",
    "    download = download_op(\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "    \n",
    "    # 02 Train Model & Autoencoder\n",
    "    train_model = train_model_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"], \n",
    "        learning_rate=model_learning_rate,\n",
    "        epochs=model_epochs,\n",
    "        batch_size=model_batch_size)\n",
    "    train_model.set_memory_request('1G')\n",
    "    train_model.set_cpu_request('1')\n",
    "    \n",
    "    train_autoencoder = train_autoencoder_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        learning_rate=autoencoder_learning_rate,\n",
    "        batch_size=autoencoder_batch_size,\n",
    "        steps=autoencoder_steps)\n",
    "    train_autoencoder.set_memory_request('1G')\n",
    "    train_autoencoder.set_cpu_request('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name vibrant_goldwasser\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://fc13d681.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/e837fe01-86c5-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"hydrosphere_address\": hydrosphere_address,\n",
    "        \"model_learning_rate\": \"0.01\",\n",
    "        \"model_epochs\": \"10\",\n",
    "        \"model_batch_size\": \"256\",\n",
    "        \"autoencoder_learning_rate\": \"0.01\",\n",
    "        \"autoencoder_steps\": \"3500\",\n",
    "        \"autoencoder_batch_size\": \"256\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Release & Deploy Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will release and deploy the trained autoencoder to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_autoencoder_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"release_autoencoder\",\n",
    "        image=f\"{username}/mnist-pipeline-release-autoencoder:{version}\",\n",
    "        file_outputs={\n",
    "            \"model_version\": \"/model_version.txt\",\n",
    "            \"model_link\": \"/model_link.txt\"\n",
    "        },\n",
    "        arguments=[\n",
    "            \"--data-path\", kwargs[\"data_path\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"],\n",
    "            \"--models-path\", kwargs[\"models_path\"],\n",
    "            \"--classes\", kwargs[\"classes\"],\n",
    "            \"--loss\", kwargs[\"loss\"], \n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--learning-rate\", kwargs[\"learning_rate\"],\n",
    "            \"--batch-size\", kwargs[\"batch_size\"],\n",
    "            \"--steps\", kwargs[\"steps\"]\n",
    "        ],\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=kwargs[\"name\"],\n",
    "        image=f\"{username}/mnist-pipeline-deploy:{version}\",\n",
    "        file_outputs={\n",
    "            \"application_name\": \"/application_name.txt\",\n",
    "            \"application_link\": \"/application_link.txt\"\n",
    "        },\n",
    "        arguments=[\n",
    "            \"--model-name\", kwargs[\"model_name\"],\n",
    "            \"--model-version\", kwargs[\"model_version\"],\n",
    "            \"--application-name-postfix\", kwargs[\"postfix\"], \n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "        ],\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    hydrosphere_address,\n",
    "    model_learning_rate,\n",
    "    model_epochs,\n",
    "    model_batch_size,\n",
    "    autoencoder_learning_rate,\n",
    "    autoencoder_steps,\n",
    "    autoencoder_batch_size,\n",
    "    model_name,\n",
    "    model_autoencoder_name,\n",
    "):\n",
    "    # 01 Download Data\n",
    "    download = download_op(\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "    \n",
    "    # 02 Train Model & Autoencoder\n",
    "    train_model = train_model_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"], \n",
    "        learning_rate=model_learning_rate,\n",
    "        epochs=model_epochs,\n",
    "        batch_size=model_batch_size)\n",
    "    train_model.set_memory_request('1G')\n",
    "    train_model.set_cpu_request('1')\n",
    "    \n",
    "    train_autoencoder = train_autoencoder_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        learning_rate=autoencoder_learning_rate,\n",
    "        batch_size=autoencoder_batch_size,\n",
    "        steps=autoencoder_steps)\n",
    "    train_autoencoder.set_memory_request('1G')\n",
    "    train_autoencoder.set_cpu_request('1')\n",
    "    \n",
    "    # 03 Release & Deploy Autoencoder\n",
    "    release_autoencoder = release_autoencoder_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        model_name=model_autoencoder_name,\n",
    "        models_path=train_autoencoder.outputs[\"model_path\"],\n",
    "        classes=train_autoencoder.outputs[\"classes\"],\n",
    "        loss=train_autoencoder.outputs[\"loss\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=autoencoder_learning_rate,\n",
    "        steps=autoencoder_steps,\n",
    "        batch_size=autoencoder_batch_size)\n",
    "    \n",
    "    deploy_autoencoder_to_prod = deploy_op(\n",
    "        name=\"deploy_autoencoder_to_prod\",\n",
    "        model_name=model_autoencoder_name,\n",
    "        postfix=\"_app\",\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_version=release_autoencoder.outputs[\"model_version\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name pedantic_bell\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://fc13d681.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/01801ad5-86c6-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"model_learning_rate\": \"0.01\",\n",
    "        \"model_epochs\": \"10\",\n",
    "        \"model_batch_size\": \"256\",\n",
    "        \"autoencoder_learning_rate\": \"0.01\",\n",
    "        \"autoencoder_steps\": \"3500\",\n",
    "        \"autoencoder_batch_size\": \"256\",\n",
    "        \"model_name\": \"mnist\",\n",
    "        \"model_autoencoder_name\": \"mnist_autoencoder\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Release & Deploy Model to Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we release the model and deploy it to the stage application for integration tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_model_op(**kwargs): \n",
    "    return dsl.ContainerOp(\n",
    "        name=\"release_model\",\n",
    "        image=f\"{username}/mnist-pipeline-release-model:{version}\", \n",
    "        file_outputs={\n",
    "            \"model_version\": \"/model_version.txt\",\n",
    "            \"model_link\": \"/model_link.txt\"\n",
    "        },\n",
    "        arguments=[\n",
    "            \"--data-path\", kwargs[\"data_path\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"],\n",
    "            \"--models-path\", kwargs[\"models_path\"],\n",
    "            \"--autoencoder-app\", kwargs[\"application_name\"],\n",
    "            \"--classes\", kwargs[\"classes\"],\n",
    "            \"--accuracy\", kwargs[\"accuracy\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--learning-rate\", kwargs[\"learning_rate\"],\n",
    "            \"--epochs\", kwargs[\"epochs\"],\n",
    "            \"--batch-size\", kwargs[\"batch_size\"],\n",
    "        ]\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    hydrosphere_address,\n",
    "    model_learning_rate,\n",
    "    model_epochs,\n",
    "    model_batch_size,\n",
    "    autoencoder_learning_rate,\n",
    "    autoencoder_steps,\n",
    "    autoencoder_batch_size,\n",
    "    model_name,\n",
    "    model_autoencoder_name,\n",
    "):\n",
    "    # 01 Download Data\n",
    "    download = download_op(\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "    \n",
    "    # 02 Train Model & Autoencoder\n",
    "    train_model = train_model_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"], \n",
    "        learning_rate=model_learning_rate,\n",
    "        epochs=model_epochs,\n",
    "        batch_size=model_batch_size)\n",
    "    train_model.set_memory_request('1G')\n",
    "    train_model.set_cpu_request('1')\n",
    "    \n",
    "    train_autoencoder = train_autoencoder_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        learning_rate=autoencoder_learning_rate,\n",
    "        batch_size=autoencoder_batch_size,\n",
    "        steps=autoencoder_steps)\n",
    "    train_autoencoder.set_memory_request('1G')\n",
    "    train_autoencoder.set_cpu_request('1')\n",
    "    \n",
    "    # 03 Release & Deploy Autoencoder\n",
    "    release_autoencoder = release_autoencoder_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        model_name=model_autoencoder_name,\n",
    "        models_path=train_autoencoder.outputs[\"model_path\"],\n",
    "        classes=train_autoencoder.outputs[\"classes\"],\n",
    "        loss=train_autoencoder.outputs[\"loss\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=autoencoder_learning_rate,\n",
    "        steps=autoencoder_steps,\n",
    "        batch_size=autoencoder_batch_size)\n",
    "    \n",
    "    deploy_autoencoder_to_prod = deploy_op(\n",
    "        name=\"deploy_autoencoder_to_prod\",\n",
    "        model_name=model_autoencoder_name,\n",
    "        postfix=\"_app\",\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_version=release_autoencoder.outputs[\"model_version\"])\n",
    "    \n",
    "    # 04 Release & Deploy Model to Stage\n",
    "    release_model = release_model_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        model_name=model_name,\n",
    "        models_path=train_model.outputs[\"model_path\"],\n",
    "        application_name=deploy_autoencoder_to_prod.outputs[\"application_name\"],\n",
    "        classes=train_model.outputs[\"classes\"],\n",
    "        accuracy=train_model.outputs[\"accuracy\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=model_learning_rate,\n",
    "        epochs=model_epochs,\n",
    "        batch_size=model_batch_size)\n",
    "\n",
    "    deploy_model_to_stage = deploy_op(\n",
    "        name=\"deploy_model_to_stage\",\n",
    "        model_name=model_name,\n",
    "        postfix=\"_stage\",\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_version=release_model.outputs[\"model_version\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name silly_northcutt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://fc13d681.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/0f27fafc-86c8-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"model_learning_rate\": \"0.01\",\n",
    "        \"model_epochs\": \"10\",\n",
    "        \"model_batch_size\": \"256\",\n",
    "        \"autoencoder_learning_rate\": \"0.01\",\n",
    "        \"autoencoder_steps\": \"3500\",\n",
    "        \"autoencoder_batch_size\": \"256\",\n",
    "        \"model_name\": \"mnist\",\n",
    "        \"model_autoencoder_name\": \"mnist_autoencoder\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 Test Stage Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we are performing integration tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"test\",\n",
    "        image=f\"{username}/mnist-pipeline-test:{version}\", \n",
    "        arguments=[\n",
    "            \"--data-path\", kwargs[\"data_path\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--acceptable-accuracy\", kwargs[\"acceptable_accuracy\"],\n",
    "            \"--application-name\", kwargs[\"application_name\"], \n",
    "        ],\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    hydrosphere_address,\n",
    "    model_learning_rate,\n",
    "    model_epochs,\n",
    "    model_batch_size,\n",
    "    autoencoder_learning_rate,\n",
    "    autoencoder_steps,\n",
    "    autoencoder_batch_size,\n",
    "    model_name,\n",
    "    model_autoencoder_name,\n",
    "    acceptable_accuracy\n",
    "):\n",
    "    # 01 Download Data\n",
    "    download = download_op(\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "    \n",
    "    # 02 Train Model & Autoencoder\n",
    "    train_model = train_model_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"], \n",
    "        learning_rate=model_learning_rate,\n",
    "        epochs=model_epochs,\n",
    "        batch_size=model_batch_size)\n",
    "    train_model.set_memory_request('1G')\n",
    "    train_model.set_cpu_request('1')\n",
    "    \n",
    "    train_autoencoder = train_autoencoder_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        learning_rate=autoencoder_learning_rate,\n",
    "        batch_size=autoencoder_batch_size,\n",
    "        steps=autoencoder_steps)\n",
    "    train_autoencoder.set_memory_request('1G')\n",
    "    train_autoencoder.set_cpu_request('1')\n",
    "    \n",
    "    # 03 Release & Deploy Autoencoder\n",
    "    release_autoencoder = release_autoencoder_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        model_name=model_autoencoder_name,\n",
    "        models_path=train_autoencoder.outputs[\"model_path\"],\n",
    "        classes=train_autoencoder.outputs[\"classes\"],\n",
    "        loss=train_autoencoder.outputs[\"loss\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=autoencoder_learning_rate,\n",
    "        steps=autoencoder_steps,\n",
    "        batch_size=autoencoder_batch_size)\n",
    "    \n",
    "    deploy_autoencoder_to_prod = deploy_op(\n",
    "        name=\"deploy_autoencoder_to_prod\",\n",
    "        model_name=model_autoencoder_name,\n",
    "        postfix=\"_app\",\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_version=release_autoencoder.outputs[\"model_version\"])\n",
    "    \n",
    "    # 04 Release & Deploy Model to Stage\n",
    "    release_model = release_model_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        model_name=model_name,\n",
    "        models_path=train_model.outputs[\"model_path\"],\n",
    "        application_name=deploy_autoencoder_to_prod.outputs[\"application_name\"],\n",
    "        classes=train_model.outputs[\"classes\"],\n",
    "        accuracy=train_model.outputs[\"accuracy\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=model_learning_rate,\n",
    "        epochs=model_epochs,\n",
    "        batch_size=model_batch_size)\n",
    "    \n",
    "    deploy_model_to_stage = deploy_op(\n",
    "        name=\"deploy_model_to_stage\",\n",
    "        model_name=model_name,\n",
    "        postfix=\"_stage\",\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_version=release_model.outputs[\"model_version\"])\n",
    "    \n",
    "    # 05 Test Stage Application\n",
    "    test = test_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        acceptable_accuracy=acceptable_accuracy,\n",
    "        application_name=deploy_model_to_stage.outputs[\"application_name\"])\n",
    "    test.set_retry(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name sleepy_hoover\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://fc13d681.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/867d0ef7-86ca-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"model_learning_rate\": \"0.01\",\n",
    "        \"model_epochs\": \"10\",\n",
    "        \"model_batch_size\": \"256\",\n",
    "        \"autoencoder_learning_rate\": \"0.01\",\n",
    "        \"autoencoder_steps\": \"3500\",\n",
    "        \"autoencoder_batch_size\": \"256\",\n",
    "        \"model_name\": \"mnist\",\n",
    "        \"model_autoencoder_name\": \"mnist_autoencoder\",\n",
    "        \"acceptable-accuracy\": \"0.90\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 Deploy Model to Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally deploying the model to production application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    hydrosphere_address,\n",
    "    model_learning_rate,\n",
    "    model_epochs,\n",
    "    model_batch_size,\n",
    "    autoencoder_learning_rate,\n",
    "    autoencoder_steps,\n",
    "    autoencoder_batch_size,\n",
    "    model_name,\n",
    "    model_autoencoder_name,\n",
    "    acceptable_accuracy\n",
    "):\n",
    "    # 01 Download Data\n",
    "    download = download_op(\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "    \n",
    "    # 02 Train Model & Autoencoder\n",
    "    train_model = train_model_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"], \n",
    "        learning_rate=model_learning_rate,\n",
    "        epochs=model_epochs,\n",
    "        batch_size=model_batch_size)\n",
    "    train_model.set_memory_request('1G')\n",
    "    train_model.set_cpu_request('1')\n",
    "    \n",
    "    train_autoencoder = train_autoencoder_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        learning_rate=autoencoder_learning_rate,\n",
    "        batch_size=autoencoder_batch_size,\n",
    "        steps=autoencoder_steps)\n",
    "    train_autoencoder.set_memory_request('1G')\n",
    "    train_autoencoder.set_cpu_request('1')\n",
    "    \n",
    "    # 03 Release & Deploy Autoencoder\n",
    "    release_autoencoder = release_autoencoder_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        model_name=model_autoencoder_name,\n",
    "        models_path=train_autoencoder.outputs[\"model_path\"],\n",
    "        classes=train_autoencoder.outputs[\"classes\"],\n",
    "        loss=train_autoencoder.outputs[\"loss\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=autoencoder_learning_rate,\n",
    "        steps=autoencoder_steps,\n",
    "        batch_size=autoencoder_batch_size)\n",
    "    \n",
    "    deploy_autoencoder_to_prod = deploy_op(\n",
    "        name=\"deploy_autoencoder_to_prod\",\n",
    "        model_name=model_autoencoder_name,\n",
    "        postfix=\"_app\",\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_version=release_autoencoder.outputs[\"model_version\"])\n",
    "    \n",
    "    # 04 Release & Deploy Model to Stage\n",
    "    release_model = release_model_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        model_name=model_name,\n",
    "        models_path=train_model.outputs[\"model_path\"],\n",
    "        application_name=deploy_autoencoder_to_prod.outputs[\"application_name\"],\n",
    "        classes=train_model.outputs[\"classes\"],\n",
    "        accuracy=train_model.outputs[\"accuracy\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=model_learning_rate,\n",
    "        epochs=model_epochs,\n",
    "        batch_size=model_batch_size)\n",
    "    \n",
    "    deploy_model_to_stage = deploy_op(\n",
    "        name=\"deploy_model_to_stage\",\n",
    "        model_name=model_name,\n",
    "        postfix=\"_stage\",\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_version=release_model.outputs[\"model_version\"])\n",
    "    \n",
    "    # 05 Test Stage Application\n",
    "    test = test_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        acceptable_accuracy=acceptable_accuracy,\n",
    "        application_name=deploy_model_to_stage.outputs[\"application_name\"])\n",
    "    test.set_retry(3)\n",
    "    \n",
    "    # 06 Deploy Model to Production\n",
    "    deploy_model_to_prod = deploy_op(\n",
    "        name=\"deploy_model_to_prod\", \n",
    "        model_name=model_name,\n",
    "        postfix=\"_app\",\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_version=release_model.outputs[\"model_version\"])\n",
    "    deploy_model_to_prod.after(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name angry_turing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://fc13d681.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/ff9abc99-86cb-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"model_learning_rate\": \"0.01\",\n",
    "        \"model_epochs\": \"10\",\n",
    "        \"model_batch_size\": \"256\",\n",
    "        \"autoencoder_learning_rate\": \"0.01\",\n",
    "        \"autoencoder_steps\": \"3500\",\n",
    "        \"autoencoder_batch_size\": \"256\",\n",
    "        \"model_name\": \"mnist\",\n",
    "        \"model_autoencoder_name\": \"mnist_autoencoder\",\n",
    "        \"acceptable-accuracy\": \"0.90\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_production_traffic(shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Sample Production Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a fully functional pipeline, we would like to automate running this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"sample\",\n",
    "        image=f\"{username}/mnist-pipeline-sample:{version}\", \n",
    "        file_outputs={\"data_path\": \"/data_path.txt\"},\n",
    "        arguments=[\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--application-name\", kwargs[\"application_name\"],\n",
    "        ]\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    hydrosphere_address,\n",
    "    model_learning_rate,\n",
    "    model_epochs,\n",
    "    model_batch_size,\n",
    "    autoencoder_learning_rate,\n",
    "    autoencoder_steps,\n",
    "    autoencoder_batch_size,\n",
    "    model_name,\n",
    "    application_name,\n",
    "    model_autoencoder_name,\n",
    "    acceptable_accuracy\n",
    "):\n",
    "    # 01 Sample Data\n",
    "    sample = sample_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        application_name=application_name)\n",
    "    \n",
    "    # 02 Train Model & Autoencoder\n",
    "    train_model = train_model_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=sample.outputs[\"data_path\"], \n",
    "        learning_rate=model_learning_rate,\n",
    "        epochs=model_epochs,\n",
    "        batch_size=model_batch_size)\n",
    "    train_model.set_memory_request('1G')\n",
    "    train_model.set_cpu_request('1')\n",
    "    \n",
    "    train_autoencoder = train_autoencoder_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=sample.outputs[\"data_path\"],\n",
    "        learning_rate=autoencoder_learning_rate,\n",
    "        batch_size=autoencoder_batch_size,\n",
    "        steps=autoencoder_steps)\n",
    "    train_autoencoder.set_memory_request('1G')\n",
    "    train_autoencoder.set_cpu_request('1')\n",
    "    \n",
    "    # 03 Release & Deploy Autoencoder\n",
    "    release_autoencoder = release_autoencoder_op(\n",
    "        data_path=sample.outputs[\"data_path\"],\n",
    "        model_name=model_autoencoder_name,\n",
    "        models_path=train_autoencoder.outputs[\"model_path\"],\n",
    "        classes=train_autoencoder.outputs[\"classes\"],\n",
    "        loss=train_autoencoder.outputs[\"loss\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=autoencoder_learning_rate,\n",
    "        steps=autoencoder_steps,\n",
    "        batch_size=autoencoder_batch_size)\n",
    "    \n",
    "    deploy_autoencoder_to_prod = deploy_op(\n",
    "        name=\"deploy_autoencoder_to_prod\",\n",
    "        model_name=model_autoencoder_name,\n",
    "        postfix=\"_app\",\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_version=release_autoencoder.outputs[\"model_version\"])\n",
    "    \n",
    "    # 04 Release & Deploy Model to Stage\n",
    "    release_model = release_model_op(\n",
    "        data_path=sample.outputs[\"data_path\"],\n",
    "        model_name=model_name,\n",
    "        models_path=train_model.outputs[\"model_path\"],\n",
    "        application_name=deploy_autoencoder_to_prod.outputs[\"application_name\"],\n",
    "        classes=train_model.outputs[\"classes\"],\n",
    "        accuracy=train_model.outputs[\"accuracy\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=model_learning_rate,\n",
    "        epochs=model_epochs,\n",
    "        batch_size=model_batch_size)\n",
    "    \n",
    "    deploy_model_to_stage = deploy_op(\n",
    "        name=\"deploy_model_to_stage\",\n",
    "        model_name=model_name,\n",
    "        postfix=\"_stage\",\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_version=release_model.outputs[\"model_version\"])\n",
    "    \n",
    "    # 05 Test Stage Application\n",
    "    test = test_op(\n",
    "        data_path=sample.outputs[\"data_path\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        acceptable_accuracy=acceptable_accuracy,\n",
    "        application_name=deploy_model_to_stage.outputs[\"application_name\"])\n",
    "    test.set_retry(3)\n",
    "    \n",
    "    # 06 Deploy Model to Production\n",
    "    deploy_model_to_prod = deploy_op(\n",
    "        name=\"deploy_model_to_prod\", \n",
    "        model_name=model_name,\n",
    "        postfix=\"_app\",\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_version=release_model.outputs[\"model_version\"])\n",
    "    deploy_model_to_prod.after(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name sharp_bose_sample\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://fc13d681.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/7cd6cd3d-86cd-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name() + \"_sample\"\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"model_learning_rate\": \"0.0005\",\n",
    "        \"model_epochs\": \"100\",\n",
    "        \"model_batch_size\": \"256\",\n",
    "        \"autoencoder_learning_rate\": \"0.01\",\n",
    "        \"autoencoder_steps\": \"3500\",\n",
    "        \"autoencoder_batch_size\": \"128\",\n",
    "        \"model_name\": \"mnist\",\n",
    "        \"model_autoencoder_name\": \"mnist_autoencoder\",\n",
    "        \"acceptable-accuracy\": \"0.80\",\n",
    "        \"application_name\": \"mnist_app\", \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_production_traffic(shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
