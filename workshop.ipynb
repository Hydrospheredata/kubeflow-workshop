{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp, os\n",
    "import kfp.dsl as dsl \n",
    "import kfp.compiler as compiler\n",
    "import kubernetes.client.models as k8s\n",
    "import namesgenerator\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMESPACE = os.environ.get(\"NAMESPACE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubeflow_address = f\"http://{NAMESPACE}.kubeflow.odsc.k8s.hydrosphere.io\"\n",
    "hydrosphere_address = f\"http://{NAMESPACE}.serving.odsc.k8s.hydrosphere.io\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will obtain all training data for our pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Kubernetes PVC resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_pvc = k8s.V1PersistentVolumeClaimVolumeSource(claim_name=\"storage\")\n",
    "storage_volume = k8s.V1Volume(name=\"storage\", persistent_volume_claim=storage_pvc)\n",
    "storage_volume_mount = k8s.V1VolumeMount(mount_path=\"{{workflow.parameters.mount-path}}\", name=\"storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"tidylobster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_op(**kwargs):\n",
    "    download = dsl.ContainerOp(\n",
    "        name=\"download\",\n",
    "        image=f\"{username}/mnist-pipeline-download:latest\",\n",
    "        file_outputs={\"data_path\": \"/data_path.txt\"},\n",
    "        arguments=[\n",
    "            \"--mount-path\", kwargs[\"mount_path\"]\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    download.add_volume(storage_volume)\n",
    "    download.add_volume_mount(storage_volume_mount)\n",
    "    return download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        mount_path=mount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipelines client\n",
    "client = kfp.Client(kubeflow_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an experiment name\n",
    "experiment_name='MNIST Showreal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get or create an experiment_id\n",
    "try:\n",
    "    experiment_id = client.get_experiment(experiment_name=experiment_name).id\n",
    "except:\n",
    "    experiment_id = client.create_experiment(experiment_name).id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name amazing_leavitt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://a432df31.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/70210556-69cc-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(experiment_id, run_name, \"pipeline.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will create a model & train it on the downloaded data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_op(download, **kwargs):\n",
    "    train = dsl.ContainerOp(\n",
    "        name=\"train\",\n",
    "        image=f\"{username}/mnist-pipeline-train:latest\",\n",
    "        file_outputs={\"accuracy\": \"/accuracy.txt\"},\n",
    "        arguments=[\n",
    "            \"--data-path\", download.outputs[\"data_path\"], \n",
    "            \"--mount-path\", kwargs[\"mount_path\"],\n",
    "            \"--learning-rate\", kwargs[\"learning_rate\"],\n",
    "            \"--epochs\", kwargs[\"epochs\"],\n",
    "            \"--batch-size\", kwargs[\"batch_size\"]\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    train.add_volume(storage_volume)\n",
    "    train.add_volume_mount(storage_volume_mount)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        mount_path=mount_path)\n",
    "    \n",
    "    train = train_op(\n",
    "        download, \n",
    "        mount_path=mount_path, \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name romantic_albattani\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://de61b6c3.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/b76b9be3-6859-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will release the trained model to the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_op(download, train, **kwargs):\n",
    "    release = dsl.ContainerOp(\n",
    "        name=\"release\",\n",
    "        image=f\"{username}/mnist-pipeline-release:latest\",\n",
    "        file_outputs={\"model-version\": \"/model-version.txt\"},\n",
    "        arguments=[\n",
    "            \"--data-path\", download.outputs[\"data_path\"],\n",
    "            \"--mount-path\", kwargs[\"mount_path\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"],\n",
    "            \"--accuracy\", train.outputs[\"accuracy\"], \n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--learning-rate\", kwargs[\"learning_rate\"],\n",
    "            \"--epochs\", kwargs[\"epochs\"],\n",
    "            \"--batch-size\", kwargs[\"batch_size\"],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    release.add_volume(storage_volume) \n",
    "    release.add_volume_mount(storage_volume_mount)\n",
    "    return release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\"\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        mount_path=mount_path)\n",
    "    \n",
    "    train = train_op(\n",
    "        download, \n",
    "        mount_path=mount_path, \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        download, \n",
    "        train,\n",
    "        mount_path=mount_path,\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name tender_shaw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://de61b6c3.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/d882208a-6858-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy to Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we are deploying the model to the stage application to run integration tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_to_stage_op(release, **kwargs):\n",
    "    deploy_to_stage = dsl.ContainerOp(\n",
    "        name=\"deploy_to_stage\",\n",
    "        image=f\"{username}/mnist-pipeline-deploy-to-stage:latest\",\n",
    "        file_outputs={\"stage-app-name\": \"/stage-app-name.txt\"},\n",
    "        arguments=[\n",
    "            \"--model-version\", release.outputs[\"model-version\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"],\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    return deploy_to_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\",\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        mount_path=mount_path)\n",
    "    \n",
    "    train = train_op(\n",
    "        download, \n",
    "        mount_path=mount_path, \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        download, \n",
    "        train,\n",
    "        mount_path=mount_path,\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)\n",
    "    \n",
    "    deploy_to_stage = deploy_to_stage_op(\n",
    "        release,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_name=model_name)\n",
    "    deploy_to_stage.after(release)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name awesome_austin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://de61b6c3.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/ebd7ee7a-6859-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we are performing integration tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_op(download, stage, **kwargs):\n",
    "    test = dsl.ContainerOp(\n",
    "        name=\"test\",\n",
    "        image=f\"{username}/mnist-pipeline-test:latest\", \n",
    "        arguments=[\n",
    "            \"--stage-app-name\", stage.outputs[\"stage-app-name\"], \n",
    "            \"--data-path\", download.outputs[\"data_path\"],\n",
    "            \"--mount-path\", kwargs[\"mount_path\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--acceptable-accuracy\", kwargs[\"acceptable_accuracy\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"], \n",
    "        ],\n",
    "    )\n",
    "\n",
    "    test.add_volume(storage_volume) \n",
    "    test.add_volume_mount(storage_volume_mount)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\",\n",
    "    acceptable_accuracy=\"0.90\",\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        mount_path=mount_path)\n",
    "    \n",
    "    train = train_op(\n",
    "        download, \n",
    "        mount_path=mount_path, \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        download, \n",
    "        train,\n",
    "        mount_path=mount_path,\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)\n",
    "    \n",
    "    deploy_to_stage = deploy_to_stage_op(\n",
    "        release,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_name=model_name)\n",
    "    deploy_to_stage.after(release)\n",
    "    \n",
    "    test = test_op(\n",
    "        download, \n",
    "        deploy_to_stage,\n",
    "        mount_path=mount_path,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        acceptable_accuracy=acceptable_accuracy,\n",
    "        model_name=model_name)\n",
    "    test.set_retry(3)\n",
    "    test.after(deploy_to_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name suspicious_jepsen\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://de61b6c3.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/ba541c37-685a-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"acceptable-accuracy\": \"0.90\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy to Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally deploying the model to production application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_to_prod_op(release, **kwargs):\n",
    "    deploy_to_prod = dsl.ContainerOp(\n",
    "        name=\"deploy_to_prod\",\n",
    "        image=f\"{username}/mnist-pipeline-deploy-to-prod:latest\",\n",
    "        arguments=[\n",
    "            \"--model-version\", release.outputs[\"model-version\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"]\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return deploy_to_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\",\n",
    "    acceptable_accuracy=\"0.90\",\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        mount_path=mount_path)\n",
    "    \n",
    "    train = train_op(\n",
    "        download, \n",
    "        mount_path=mount_path, \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        download, \n",
    "        train,\n",
    "        mount_path=mount_path,\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)\n",
    "    \n",
    "    deploy_to_stage = deploy_to_stage_op(\n",
    "        release,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_name=model_name)\n",
    "    deploy_to_stage.after(release)\n",
    "    \n",
    "    test = test_op(\n",
    "        download, \n",
    "        deploy_to_stage,\n",
    "        mount_path=mount_path,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        acceptable_accuracy=acceptable_accuracy,\n",
    "        model_name=model_name)\n",
    "    test.set_retry(3)\n",
    "    test.after(deploy_to_stage)\n",
    "    \n",
    "    deploy_to_prod = deploy_to_prod_op(\n",
    "        release,\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "    deploy_to_prod.after(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name quizzical_dubinsky\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://de61b6c3.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/054275d1-6862-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"acceptable-accuracy\": \"0.90\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_production_traffic(shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a fully functional pipeline, we would like to automate running this pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_op(**kwargs):\n",
    "    sample = dsl.ContainerOp(\n",
    "        name=\"sample\",\n",
    "        image=f\"{username}/mnist-pipeline-sample:latest\", \n",
    "        file_outputs={\"data_path\": \"/data_path.txt\"},\n",
    "        arguments=[\n",
    "            \"--mount-path\", kwargs[\"mount_path\"], \n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "        ]\n",
    "    )  \n",
    "    \n",
    "    sample.add_volume(storage_volume)\n",
    "    sample.add_volume_mount(storage_volume_mount)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\",\n",
    "    acceptable_accuracy=\"0.90\",\n",
    "):\n",
    "    \n",
    "    sample = sample_op(\n",
    "        mount_path=mount_path, \n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "    \n",
    "    train = train_op(\n",
    "        sample, \n",
    "        mount_path=mount_path, \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(sample)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        sample, \n",
    "        train,\n",
    "        mount_path=mount_path, \n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)\n",
    "    \n",
    "    deploy_to_stage = deploy_to_stage_op(\n",
    "        release,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_name=model_name)\n",
    "    deploy_to_stage.after(release)\n",
    "    \n",
    "    test = test_op(\n",
    "        sample, \n",
    "        deploy_to_stage,\n",
    "        mount_path=mount_path,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        acceptable_accuracy=acceptable_accuracy,\n",
    "        model_name=model_name)\n",
    "    test.set_retry(3)\n",
    "    test.after(deploy_to_stage)\n",
    "    \n",
    "    deploy_to_prod = deploy_to_prod_op(\n",
    "        release,\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "    deploy_to_prod.after(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name serene_perlman\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://de61b6c3.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/fac71d17-6863-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"acceptable-accuracy\": \"0.30\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
