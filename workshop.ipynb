{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl \n",
    "import kfp.compiler as compiler\n",
    "import kubernetes.client.models as k8s\n",
    "import namesgenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubeflow_address = \"http://d3c79316.kubeflow.odsc.k8s.hydrosphere.io\"\n",
    "hydrosphere_address = \"http://d3c79316.serving.odsc.k8s.hydrosphere.io\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will obtain all training data for our pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a working file at `01_download/download.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cat > 01_download/Dockerfile << EOL\n",
    "FROM tidylobster/odsc-base:1.0\n",
    "ADD ./download.py /src/\n",
    "WORKDIR /src/\n",
    "ENTRYPOINT [ \"python\", \"download.py\" ]\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build & publish an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  9.728kB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./download.py /src/\n",
      " ---> f356d8b06daa\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in c16a987a259b\n",
      "Removing intermediate container c16a987a259b\n",
      " ---> 88089d296e5d\n",
      "Step 4/4 : ENTRYPOINT [ \"python\", \"download.py\" ]\n",
      " ---> Running in 6dd2b48b4cb2\n",
      "Removing intermediate container 6dd2b48b4cb2\n",
      " ---> 8e1c2022dacc\n",
      "Successfully built 8e1c2022dacc\n",
      "Successfully tagged tidylobster/mnist-pipeline-download:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-download]\n",
      "917794055c32: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "93ed1238773c: Waiting\n",
      "eeb5ce6b3db4: Waiting\n",
      "886601877ba4: Waiting\n",
      "0fc100fdc7f9: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "66a75017de07: Layer already exists\n",
      "83c720aa6f39: Layer already exists\n",
      "56995c671038: Layer already exists\n",
      "eee35c27cf87: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "917794055c32: Pushed\n",
      "latest: digest: sha256:ae027a5f8fa29c44031bc61af79ffd3310d9abdd8079607e676c9c1138b769c2 size: 3041\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-download:latest --no-cache 01_download\n",
    "docker push tidylobster/mnist-pipeline-download:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Kubernetes PVC resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_pvc = k8s.V1PersistentVolumeClaimVolumeSource(claim_name=\"storage\")\n",
    "storage_volume = k8s.V1Volume(name=\"storage\", persistent_volume_claim=storage_pvc)\n",
    "storage_volume_mount = k8s.V1VolumeMount(mount_path=\"{{workflow.parameters.mount-path}}\", name=\"storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create required environmnet variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mount_path_env = k8s.V1EnvVar(name=\"MOUNT_PATH\", value=\"{{workflow.parameters.mount-path}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"tidylobster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_op():\n",
    "    download = dsl.ContainerOp(\n",
    "        name=\"download\",\n",
    "        image=f\"{username}/mnist-pipeline-download:latest\")  # <-- Replace with built docker image\n",
    "    \n",
    "    download.add_volume(storage_volume)\n",
    "    download.add_volume_mount(storage_volume_mount)\n",
    "    download.add_env_variable(mount_path_env)\n",
    "    \n",
    "    return download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "):\n",
    "    download = download_op()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i '' s/minio-service.kubeflow/minio-service.${NAMESPACE}/g pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipelines client\n",
    "client = kfp.Client(kubeflow_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an experiment name\n",
    "experiment_name='MNIST Showreal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get or create an experiment_id\n",
    "try:\n",
    "    experiment_id = client.get_experiment(experiment_name=experiment_name).id\n",
    "except:\n",
    "    experiment_id = client.create_experiment(experiment_name).id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dreamy_ptolemy'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a name for the run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://d3c79316.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/6e3ed936-65b2-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a run\n",
    "result = client.run_pipeline(experiment_id, run_name, \"pipeline.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will create a model & train it on the downloaded data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cat > 02_train/Dockerfile << EOL\n",
    "FROM tidylobster/odsc-base:1.0\n",
    "ADD ./train.py /src/\n",
    "WORKDIR /src/\n",
    "ENTRYPOINT [ \"python\", \"train.py\" ]\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  54.59MB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./train.py /src/\n",
      " ---> c3d8af72b58b\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in 56a3b98c97aa\n",
      "Removing intermediate container 56a3b98c97aa\n",
      " ---> 95cf30a870a7\n",
      "Step 4/4 : ENTRYPOINT [ \"python\", \"train.py\" ]\n",
      " ---> Running in ff1b51acfbdc\n",
      "Removing intermediate container ff1b51acfbdc\n",
      " ---> 8e94d53c3631\n",
      "Successfully built 8e94d53c3631\n",
      "Successfully tagged tidylobster/mnist-pipeline-train:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-train]\n",
      "3fd977cad826: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "eeb5ce6b3db4: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "886601877ba4: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "93ed1238773c: Waiting\n",
      "56995c671038: Layer already exists\n",
      "66a75017de07: Layer already exists\n",
      "83c720aa6f39: Layer already exists\n",
      "eee35c27cf87: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "3fd977cad826: Pushed\n",
      "latest: digest: sha256:4e037d3d7773d2a13e1a4081b10ab4fb86b43d73edc5e416e4ff3d917980241e size: 3041\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-train:latest --no-cache 02_train/ \n",
    "docker push tidylobster/mnist-pipeline-train:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create required environmnet variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_env = k8s.V1EnvVar(name=\"LEARNING_RATE\", value=\"{{workflow.parameters.learning-rate}}\")\n",
    "epochs_env = k8s.V1EnvVar(name=\"EPOCHS\", value=\"{{workflow.parameters.epochs}}\")\n",
    "batch_size_env = k8s.V1EnvVar(name=\"BATCH_SIZE\", value=\"{{workflow.parameters.batch-size}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_op():\n",
    "    train = dsl.ContainerOp(\n",
    "        name=\"train\",\n",
    "        image=\"tidylobster/mnist-pipeline-train:latest\",        # <-- Replace with correct docker image\n",
    "        file_outputs={\"accuracy\": \"/accuracy.txt\"})\n",
    "\n",
    "    train.add_volume(storage_volume)\n",
    "    train.add_volume_mount(storage_volume_mount)\n",
    "    train.add_env_variable(mount_path_env)\n",
    "    train.add_env_variable(learning_rate_env)\n",
    "    train.add_env_variable(epochs_env)\n",
    "    train.add_env_variable(batch_size_env)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "):\n",
    "    \n",
    "    download = download_op()\n",
    "    train = train_op()\n",
    "    \n",
    "    train.after(download)\n",
    "    train.set_memory_request('2G')\n",
    "    train.set_cpu_request('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i '' s/minio-service.kubeflow/minio-service.${NAMESPACE}/g pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'naughty_shaw'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = namesgenerator.get_random_name()\n",
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://d3c79316.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/7f0e393a-65b2-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a run\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will upload the model to Hydrosphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cat > 03_upload/Dockerfile << EOL\n",
    "FROM tidylobster/odsc-base:1.0\n",
    "ADD ./execute.sh /src/\n",
    "WORKDIR /src/\n",
    "ENTRYPOINT [ \"bash\", \"execute.sh\" ]\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  4.608kB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./execute.sh /src/\n",
      " ---> 82b887f31872\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in ed41d9c6b3c1\n",
      "Removing intermediate container ed41d9c6b3c1\n",
      " ---> b54df2a34b1e\n",
      "Step 4/4 : ENTRYPOINT [ \"bash\", \"execute.sh\" ]\n",
      " ---> Running in b87b766258d3\n",
      "Removing intermediate container b87b766258d3\n",
      " ---> 264eae903a78\n",
      "Successfully built 264eae903a78\n",
      "Successfully tagged tidylobster/mnist-pipeline-upload:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-upload]\n",
      "b29001f3bfb3: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "0fc100fdc7f9: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "93ed1238773c: Waiting\n",
      "eeb5ce6b3db4: Waiting\n",
      "886601877ba4: Waiting\n",
      "56995c671038: Layer already exists\n",
      "83c720aa6f39: Layer already exists\n",
      "66a75017de07: Layer already exists\n",
      "eee35c27cf87: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "b29001f3bfb3: Pushed\n",
      "latest: digest: sha256:378430f2a359e288a86f5bdbab8b7e89912a91da50b07d25476a1d77031d2d98 size: 3040\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-upload:latest --no-cache 03_upload/ \n",
    "docker push tidylobster/mnist-pipeline-upload:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create required environmnet variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_env = k8s.V1EnvVar(name=\"MODEL_NAME\", value=\"{{workflow.parameters.model-name}}\")\n",
    "hydrosphere_address_env = k8s.V1EnvVar(name=\"CLUSTER_ADDRESS\", value=\"{{workflow.parameters.hydrosphere-address}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_op(train):\n",
    "    upload = dsl.ContainerOp(\n",
    "        name=\"upload\",\n",
    "        image=\"tidylobster/mnist-pipeline-upload:latest\",        # <-- Replace with correct docker image\n",
    "        file_outputs={\"model-version\": \"/model-version.txt\"},\n",
    "        arguments=[train.outputs[\"accuracy\"]])\n",
    "\n",
    "    upload.add_volume(storage_volume) \n",
    "    upload.add_volume_mount(storage_volume_mount)\n",
    "    upload.add_env_variable(mount_path_env)\n",
    "    upload.add_env_variable(model_name_env)\n",
    "    upload.add_env_variable(hydrosphere_address_env)\n",
    "    upload.add_env_variable(learning_rate_env)\n",
    "    upload.add_env_variable(epochs_env)\n",
    "    upload.add_env_variable(batch_size_env)\n",
    "    \n",
    "    return upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\"\n",
    "):\n",
    "    \n",
    "    download = download_op()\n",
    "    \n",
    "    train = train_op()\n",
    "    train.after(download)\n",
    "    train.set_memory_request('2G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    upload = upload_op(train)\n",
    "    upload.after(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i '' s/minio-service.kubeflow/minio-service.${NAMESPACE}/g pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'keen_borg'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = namesgenerator.get_random_name()\n",
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://d3c79316.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/e5962f67-65b2-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a run\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predeploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we are pre-deploying the application to run integration tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cat > 04_predeploy/Dockerfile << EOL\n",
    "FROM tidylobster/odsc-base:1.0\n",
    "ADD ./execute.sh /src/\n",
    "WORKDIR /src/\n",
    "ENTRYPOINT [ \"bash\", \"execute.sh\" ]\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  3.584kB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./execute.sh /src/\n",
      " ---> 89b327d5bf19\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in dd732bbc6d5d\n",
      "Removing intermediate container dd732bbc6d5d\n",
      " ---> 926efbe8e331\n",
      "Step 4/4 : ENTRYPOINT [ \"bash\", \"execute.sh\" ]\n",
      " ---> Running in 948fb87a76fc\n",
      "Removing intermediate container 948fb87a76fc\n",
      " ---> 4dfbd392404b\n",
      "Successfully built 4dfbd392404b\n",
      "Successfully tagged tidylobster/mnist-pipeline-predeploy:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-predeploy]\n",
      "b6eff90bffd4: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "eeb5ce6b3db4: Waiting\n",
      "886601877ba4: Waiting\n",
      "93ed1238773c: Waiting\n",
      "0fc100fdc7f9: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "83c720aa6f39: Layer already exists\n",
      "66a75017de07: Layer already exists\n",
      "eee35c27cf87: Layer already exists\n",
      "56995c671038: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "b6eff90bffd4: Pushed\n",
      "latest: digest: sha256:20ab0b40c9e787cfbc7aa4c1b3b12f55f8137db536fb2a9e23cffdba14d43d07 size: 3040\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-predeploy:latest --no-cache 04_predeploy/ \n",
    "docker push tidylobster/mnist-pipeline-predeploy:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create required environmnet variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_name_env = k8s.V1EnvVar(name=\"APPLICATION_NAME\", value=\"{{workflow.parameters.application-name}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predeploy_op(upload):\n",
    "    predeploy = dsl.ContainerOp(\n",
    "        name=\"predeploy\",\n",
    "        image=\"tidylobster/mnist-pipeline-predeploy:latest\",        # <-- Replace with correct docker image\n",
    "        arguments=[upload.outputs[\"model-version\"]],\n",
    "        file_outputs={\"predeploy-app-name\": \"/predeploy-app-name.txt\"})\n",
    "\n",
    "    predeploy.add_env_variable(hydrosphere_address_env)\n",
    "    predeploy.add_env_variable(application_name_env)\n",
    "    predeploy.add_env_variable(model_name_env)\n",
    "    \n",
    "    return predeploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\",\n",
    "    application_name=\"mnist-app\"\n",
    "):\n",
    "    \n",
    "    download = download_op()\n",
    "    \n",
    "    train = train_op()\n",
    "    train.after(download)\n",
    "    train.set_memory_request('2G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    upload = upload_op(train)\n",
    "    upload.after(train)\n",
    "    \n",
    "    predeploy = predeploy_op(upload)\n",
    "    predeploy.after(upload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i '' s/minio-service.kubeflow/minio-service.${NAMESPACE}/g pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loving_wright'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = namesgenerator.get_random_name()\n",
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://d3c79316.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/ef26f033-65b2-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a run\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"application-name\": \"mnist-app\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we are performing integration tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cat > 05_test/Dockerfile << EOL\n",
    "FROM tidylobster/odsc-base:1.0\n",
    "ADD ./test.py /src/\n",
    "WORKDIR /src/\n",
    "ENTRYPOINT [ \"python\", \"test.py\" ]\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  32.07MB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./test.py /src/\n",
      " ---> 0e2ecfd1de04\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in 8924ff3a4217\n",
      "Removing intermediate container 8924ff3a4217\n",
      " ---> 4c748258a8b9\n",
      "Step 4/4 : ENTRYPOINT [ \"python\", \"test.py\" ]\n",
      " ---> Running in 7b800c509e65\n",
      "Removing intermediate container 7b800c509e65\n",
      " ---> 38594bc1e067\n",
      "Successfully built 38594bc1e067\n",
      "Successfully tagged tidylobster/mnist-pipeline-test:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-test]\n",
      "9599b779b417: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "0fc100fdc7f9: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "93ed1238773c: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "eeb5ce6b3db4: Waiting\n",
      "886601877ba4: Waiting\n",
      "83c720aa6f39: Layer already exists\n",
      "56995c671038: Layer already exists\n",
      "66a75017de07: Layer already exists\n",
      "eee35c27cf87: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "9599b779b417: Pushed\n",
      "latest: digest: sha256:79e0acc28a1666af2698013d90e4b0179d8b1a876ff9c31087d6735e795fa195 size: 3040\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-test:latest --no-cache 05_test/ \n",
    "docker push tidylobster/mnist-pipeline-test:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create required environmnet variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_amount_env = k8s.V1EnvVar(name=\"TEST_AMOUNT\", value=\"{{workflow.parameters.test-amount}}\")\n",
    "requests_delay_env = k8s.V1EnvVar(name=\"REQUESTS_DELAY\", value=\"{{workflow.parameters.requests-delay}}\")\n",
    "acceptable_accuracy_env = k8s.V1EnvVar(name=\"ACCEPTABLE_ACCURACY\", value=\"{{workflow.parameters.acceptable-accuracy}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_op(predeploy):\n",
    "    test = dsl.ContainerOp(\n",
    "        name=\"test\",\n",
    "        image=\"tidylobster/mnist-pipeline-test:latest\",               # <-- Replace with correct docker image\n",
    "        arguments=[predeploy.outputs[\"predeploy-app-name\"]])\n",
    "\n",
    "    test.add_volume(storage_volume) \n",
    "    test.add_volume_mount(storage_volume_mount)\n",
    "    test.add_env_variable(mount_path_env)\n",
    "    test.add_env_variable(hydrosphere_address_env)\n",
    "    test.add_env_variable(application_name_env)\n",
    "    test.add_env_variable(test_amount_env)\n",
    "    test.add_env_variable(acceptable_accuracy_env)\n",
    "    test.add_env_variable(requests_delay_env)\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\",\n",
    "    application_name=\"mnist-app\",\n",
    "    acceptable_accuracy=\"0.90\",\n",
    "    test_amount=\"100\",\n",
    "    requests_delay=\"2\",\n",
    "):\n",
    "    \n",
    "    download = download_op()\n",
    "    \n",
    "    train = train_op()\n",
    "    train.after(download)\n",
    "    train.set_memory_request('2G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    upload = upload_op(train)\n",
    "    upload.after(train)\n",
    "    \n",
    "    predeploy = predeploy_op(upload)\n",
    "    predeploy.after(upload)\n",
    "    \n",
    "    test = test_op(predeploy)\n",
    "    test.set_retry(3)\n",
    "    test.after(predeploy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i '' s/minio-service.kubeflow/minio-service.${NAMESPACE}/g pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loving_yalow'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = namesgenerator.get_random_name()\n",
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://d3c79316.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/f889eb65-65b2-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a run\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"application-name\": \"mnist-app\",\n",
    "        \"acceptable-accuracy\": \"0.90\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Predeploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the application has been tested on a real data, we are removing pre-deploy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cat > 06_rm-predeploy/Dockerfile << EOL\n",
    "FROM tidylobster/odsc-base:1.0\n",
    "ADD ./execute.sh /src/\n",
    "WORKDIR /src/\n",
    "ENTRYPOINT [ \"bash\", \"execute.sh\" ]\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  3.072kB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./execute.sh /src/\n",
      " ---> 6691c33950ba\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in e35d9c80c9b5\n",
      "Removing intermediate container e35d9c80c9b5\n",
      " ---> 8e2730ea8ca7\n",
      "Step 4/4 : ENTRYPOINT [ \"bash\", \"execute.sh\" ]\n",
      " ---> Running in 77446322f768\n",
      "Removing intermediate container 77446322f768\n",
      " ---> 9c5b9cb911ae\n",
      "Successfully built 9c5b9cb911ae\n",
      "Successfully tagged tidylobster/mnist-pipeline-rm-predeploy:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-rm-predeploy]\n",
      "48ac0c48bead: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "eeb5ce6b3db4: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "886601877ba4: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "93ed1238773c: Waiting\n",
      "eee35c27cf87: Layer already exists\n",
      "83c720aa6f39: Layer already exists\n",
      "66a75017de07: Layer already exists\n",
      "56995c671038: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "48ac0c48bead: Pushed\n",
      "latest: digest: sha256:b6a46bfec356e55c5b6af03fae4f51b2d71818c49bfcf22aa17503c4e760483f size: 3040\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-rm-predeploy:latest --no-cache 06_rm-predeploy/ \n",
    "docker push tidylobster/mnist-pipeline-rm-predeploy:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_predeploy_op(predeploy):\n",
    "    rm_predeploy = dsl.ContainerOp(\n",
    "        name=\"remove-predeploy\",\n",
    "        image=\"tidylobster/mnist-pipeline-rm-predeploy:latest\",    # <-- Replace with correct docker image  \n",
    "        arguments=[predeploy.outputs[\"predeploy-app-name\"]])\n",
    "    rm_predeploy.add_env_variable(hydrosphere_address_env)\n",
    "    \n",
    "    return rm_predeploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\",\n",
    "    application_name=\"mnist-app\",\n",
    "    acceptable_accuracy=\"0.90\",\n",
    "    test_amount=\"100\",\n",
    "    requests_delay=\"2\",\n",
    "):\n",
    "    \n",
    "    download = download_op()\n",
    "    \n",
    "    train = train_op()\n",
    "    train.after(download)\n",
    "    train.set_memory_request('2G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    upload = upload_op(train)\n",
    "    upload.after(train)\n",
    "    \n",
    "    predeploy = predeploy_op(upload)\n",
    "    predeploy.after(upload)\n",
    "    \n",
    "    test = test_op(predeploy)\n",
    "    test.set_retry(3)\n",
    "    test.after(predeploy)\n",
    "    \n",
    "    rm_predeploy = rm_predeploy_op(predeploy)\n",
    "    rm_predeploy.after(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i '' s/minio-service.kubeflow/minio-service.${NAMESPACE}/g pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lucid_jang'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = namesgenerator.get_random_name()\n",
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://d3c79316.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/00c2f31b-65b3-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a run\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"application-name\": \"mnist-app\",\n",
    "        \"acceptable-accuracy\": \"0.90\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally deploying application to production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cat > 07_deploy/Dockerfile << EOL\n",
    "FROM tidylobster/odsc-base:1.0\n",
    "ADD ./execute.sh /src/\n",
    "WORKDIR /src/\n",
    "ENTRYPOINT [ \"bash\", \"execute.sh\" ]\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  3.072kB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./execute.sh /src/\n",
      " ---> a674f52b4b3f\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in b7850268ef2d\n",
      "Removing intermediate container b7850268ef2d\n",
      " ---> c1997014ad75\n",
      "Step 4/4 : ENTRYPOINT [ \"bash\", \"execute.sh\" ]\n",
      " ---> Running in 5dda16631a65\n",
      "Removing intermediate container 5dda16631a65\n",
      " ---> f6bb31a46098\n",
      "Successfully built f6bb31a46098\n",
      "Successfully tagged tidylobster/mnist-pipeline-deploy:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-deploy]\n",
      "94675759f65f: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "93ed1238773c: Waiting\n",
      "eeb5ce6b3db4: Waiting\n",
      "886601877ba4: Waiting\n",
      "0fc100fdc7f9: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "eee35c27cf87: Layer already exists\n",
      "83c720aa6f39: Layer already exists\n",
      "66a75017de07: Layer already exists\n",
      "56995c671038: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "94675759f65f: Pushed\n",
      "latest: digest: sha256:9b37a03cfbb44e03bd64651926d477b21e471758321e88d399c983685f00dc51 size: 3040\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-deploy:latest --no-cache 07_deploy/ \n",
    "docker push tidylobster/mnist-pipeline-deploy:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_op(upload):\n",
    "    deploy = dsl.ContainerOp(\n",
    "        name=\"deploy\",\n",
    "        image=\"tidylobster/mnist-pipeline-deploy:latest\",              # <-- Replace with correct docker image\n",
    "        arguments=[upload.outputs[\"model-version\"]])\n",
    "\n",
    "    deploy.add_env_variable(hydrosphere_address_env)\n",
    "    deploy.add_env_variable(application_name_env)\n",
    "    deploy.add_env_variable(model_name_env)\n",
    "    \n",
    "    return deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\",\n",
    "    application_name=\"mnist-app\",\n",
    "    acceptable_accuracy=\"0.90\",\n",
    "    test_amount=\"100\",\n",
    "    requests_delay=\"2\",\n",
    "):\n",
    "    \n",
    "    download = download_op()\n",
    "    \n",
    "    train = train_op()\n",
    "    train.after(download)\n",
    "    train.set_memory_request('2G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    upload = upload_op(train)\n",
    "    upload.after(train)\n",
    "    \n",
    "    predeploy = predeploy_op(upload)\n",
    "    predeploy.after(upload)\n",
    "    \n",
    "    test = test_op(predeploy)\n",
    "    test.set_retry(3)\n",
    "    test.after(predeploy)\n",
    "    \n",
    "    rm_predeploy = rm_predeploy_op(predeploy)\n",
    "    rm_predeploy.after(test)\n",
    "    \n",
    "    deploy = deploy_op(upload)\n",
    "    deploy.after(test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i '' s/minio-service.kubeflow/minio-service.${NAMESPACE}/g pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'festive_stonebraker'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = namesgenerator.get_random_name()\n",
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://d3c79316.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/09698c77-65b3-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a run\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"application-name\": \"mnist-app\",\n",
    "        \"acceptable-accuracy\": \"0.90\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a fully functional pipeline, we would like to automate running this pipeline. But we don't "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cat > 01_sampling/Dockerfile << EOL\n",
    "FROM tidylobster/odsc-base:1.0\n",
    "ADD ./sample.py /src/\n",
    "WORKDIR /src/\n",
    "ENTRYPOINT [ \"python\", \"sample.py\" ]\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  144.9kB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./sample.py /src/\n",
      " ---> c9807cee3f81\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in c260f969cb23\n",
      "Removing intermediate container c260f969cb23\n",
      " ---> 2d1d9aa35c0c\n",
      "Step 4/4 : ENTRYPOINT [ \"python\", \"sample.py\" ]\n",
      " ---> Running in e407c23c9fe8\n",
      "Removing intermediate container e407c23c9fe8\n",
      " ---> 990363323ae0\n",
      "Successfully built 990363323ae0\n",
      "Successfully tagged tidylobster/mnist-pipeline-sample:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-sample]\n",
      "06ec69383254: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "886601877ba4: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "eeb5ce6b3db4: Waiting\n",
      "93ed1238773c: Waiting\n",
      "0fc100fdc7f9: Waiting\n",
      "56995c671038: Mounted from tidylobster/mnist-pipeline-deploy\n",
      "eee35c27cf87: Mounted from tidylobster/mnist-pipeline-deploy\n",
      "66a75017de07: Mounted from tidylobster/mnist-pipeline-deploy\n",
      "83c720aa6f39: Mounted from tidylobster/mnist-pipeline-deploy\n",
      "06ec69383254: Pushed\n",
      "886601877ba4: Mounted from tidylobster/mnist-pipeline-deploy\n",
      "93ed1238773c: Mounted from tidylobster/mnist-pipeline-deploy\n",
      "eeb5ce6b3db4: Mounted from tidylobster/mnist-pipeline-deploy\n",
      "0fc100fdc7f9: Mounted from tidylobster/mnist-pipeline-deploy\n",
      "68dda0c9a8cd: Mounted from tidylobster/mnist-pipeline-deploy\n",
      "f67191ae09b8: Mounted from tidylobster/mnist-pipeline-train\n",
      "b2fd8b4c3da7: Mounted from tidylobster/mnist-pipeline-train\n",
      "0de2edf7bff4: Mounted from tidylobster/mnist-pipeline-deploy\n",
      "latest: digest: sha256:d29a2dbf1ae990d5c1ccf21869bf463a8256ffd63c446710f97ba3c52cbc3488 size: 3041\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-sample:latest --no-cache 01_sample/ \n",
    "docker push tidylobster/mnist-pipeline-sample:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_op():\n",
    "    sample = dsl.ContainerOp(\n",
    "        name=\"sample\",\n",
    "        image=\"tidylobster/mnist-pipeline-sample:latest\")     # <-- Replace with correct docker image\n",
    "    \n",
    "    sample.add_volume(storage_volume)\n",
    "    sample.add_volume_mount(storage_volume_mount)\n",
    "    sample.add_env_variable(mount_path_env)\n",
    "    sample.add_env_variable(hydrosphere_address_env)\n",
    "    sample.add_env_variable(application_name_env)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\",\n",
    "    application_name=\"mnist-app\",\n",
    "    acceptable_accuracy=\"0.90\",\n",
    "    test_amount=\"100\",\n",
    "    requests_delay=\"2\",\n",
    "):\n",
    "    \n",
    "    sample = sample_op()\n",
    "    \n",
    "    train = train_op()\n",
    "    train.after(sample)\n",
    "    train.set_memory_request('2G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    upload = upload_op(train)\n",
    "    upload.after(train)\n",
    "    \n",
    "    predeploy = predeploy_op(upload)\n",
    "    predeploy.after(upload)\n",
    "    \n",
    "    test = test_op(predeploy)\n",
    "    test.set_retry(3)\n",
    "    test.after(predeploy)\n",
    "    \n",
    "    rm_predeploy = rm_predeploy_op(predeploy)\n",
    "    rm_predeploy.after(test)\n",
    "    \n",
    "    deploy = deploy_op(upload)\n",
    "    deploy.after(test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i '' s/minio-service.kubeflow/minio-service.${NAMESPACE}/g pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'focused_jones'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = namesgenerator.get_random_name()\n",
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ApiException",
     "evalue": "(404)\nReason: Not Found\nHTTP response headers: HTTPHeaderDict({'Server': 'nginx/1.15.3', 'Date': 'Tue, 23 Apr 2019 10:41:19 GMT', 'Content-Type': 'text/plain; charset=utf-8', 'Content-Length': '21', 'Connection': 'keep-alive'})\nHTTP response body: default backend - 404\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiException\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-6f00c42e7b36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m\"hydrosphere-address\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"http://d3c79316.serving.odsc.k8s.hydrosphere.io\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m\"application-name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"mnist-app\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;34m\"acceptable-accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"0.90\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     }\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/kfp/_client.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(self, experiment_id, job_name, pipeline_package_path, params, pipeline_id)\u001b[0m\n\u001b[1;32m    230\u001b[0m         pipeline_spec=spec, resource_references=[reference], name=job_name)\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/kfp_run/api/run_service_api.py\u001b[0m in \u001b[0;36mcreate_run\u001b[0;34m(self, body, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_run_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_run_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/kfp_run/api/run_service_api.py\u001b[0m in \u001b[0;36mcreate_run_with_http_info\u001b[0;34m(self, body, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_preload_content'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_request_timeout'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             collection_formats=collection_formats)\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/kfp_run/api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    320\u001b[0m                                    \u001b[0mresponse_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                                    \u001b[0m_return_http_data_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection_formats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                                    _preload_content, _request_timeout)\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             thread = self.pool.apply_async(self.__call_api, (resource_path,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/kfp_run/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mpost_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _request_timeout=_request_timeout)\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/kfp_run/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    363\u001b[0m                                          \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                                          \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                                          body=body)\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"PUT\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             return self.rest_client.PUT(url,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/kfp_run/rest.py\u001b[0m in \u001b[0;36mPOST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    273\u001b[0m                             \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                             \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                             body=body)\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     def PUT(self, url, headers=None, query_params=None, post_params=None,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/kfp_run/rest.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mApiException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mApiException\u001b[0m: (404)\nReason: Not Found\nHTTP response headers: HTTPHeaderDict({'Server': 'nginx/1.15.3', 'Date': 'Tue, 23 Apr 2019 10:41:19 GMT', 'Content-Type': 'text/plain; charset=utf-8', 'Content-Length': '21', 'Connection': 'keep-alive'})\nHTTP response body: default backend - 404\n"
     ]
    }
   ],
   "source": [
    "# make a run\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": \"http://d3c79316.serving.odsc.k8s.hydrosphere.io\",\n",
    "        \"application-name\": \"mnist-app\",\n",
    "        \"acceptable-accuracy\": \"0.90\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
