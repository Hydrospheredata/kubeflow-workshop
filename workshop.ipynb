{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp, os\n",
    "import kfp.dsl as dsl \n",
    "import kfp.compiler as compiler\n",
    "import kubernetes.client.models as k8s\n",
    "from kfp.aws import use_aws_secret\n",
    "import namesgenerator\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMESPACE = os.environ.get(\"NAMESPACE\") \n",
    "\n",
    "kubeflow_address = f\"http://{NAMESPACE}.kubeflow.odsc.k8s.hydrosphere.io\"\n",
    "hydrosphere_address = f\"http://{NAMESPACE}.serving.odsc.k8s.hydrosphere.io\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://df3b0da4.kubeflow.odsc.k8s.hydrosphere.io\n",
      "http://df3b0da4.serving.odsc.k8s.hydrosphere.io\n"
     ]
    }
   ],
   "source": [
    "print(kubeflow_address)\n",
    "print(hydrosphere_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will obtain all training data for our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"hydrosphere\"\n",
    "version = \"v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"download\",\n",
    "        image=f\"{username}/mnist-pipeline-download:{version}\",\n",
    "        file_outputs={\"data_path\": \"/data_path.txt\"},\n",
    "        arguments=[\"--hydrosphere-address\", kwargs[\"hydrosphere_address\"]]\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(hydrosphere_address):\n",
    "    download = download_op(\n",
    "        hydrosphere_address=hydrosphere_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace compiled hardcoded namespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipelines client\n",
    "client = kfp.Client(kubeflow_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an experiment name\n",
    "experiment_name='MNIST Showreal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get or create an experiment_id\n",
    "try:\n",
    "    experiment_id = client.get_experiment(experiment_name=experiment_name).id\n",
    "except:\n",
    "    experiment_id = client.create_experiment(experiment_name).id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name agitated_wiles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://df3b0da4.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/c07df41a-70c4-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will create a model & train it on the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"train\",\n",
    "        image=f\"{username}/mnist-pipeline-train:{version}\",\n",
    "        file_outputs={\n",
    "            \"accuracy\": \"/accuracy.txt\",\n",
    "            \"model_path\": \"/model_path.txt\"\n",
    "        },\n",
    "        arguments=[\n",
    "            \"--data-path\", kwargs[\"data_path\"],\n",
    "            \"--learning-rate\", kwargs[\"learning_rate\"],\n",
    "            \"--epochs\", kwargs[\"epochs\"],\n",
    "            \"--batch-size\", kwargs[\"batch_size\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"]\n",
    "        ],\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    hydrosphere_address,\n",
    "    learning_rate,\n",
    "    epochs,\n",
    "    batch_size,\n",
    "):\n",
    "    download = download_op(\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "\n",
    "    train = train_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"], \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace compiled hardcoded namespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name hopeful_ardinghelli\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://df3b0da4.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/9f829866-70c5-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will release the trained model to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"release\",\n",
    "        image=f\"{username}/mnist-pipeline-release:{version}\",\n",
    "        file_outputs={\"model_version\": \"/model_version.txt\"},\n",
    "        arguments=[\n",
    "            \"--data-path\", kwargs[\"data_path\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"],\n",
    "            \"--models-path\", kwargs[\"models_path\"],\n",
    "            \"--accuracy\", kwargs[\"accuracy\"], \n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--learning-rate\", kwargs[\"learning_rate\"],\n",
    "            \"--epochs\", kwargs[\"epochs\"],\n",
    "            \"--batch-size\", kwargs[\"batch_size\"],\n",
    "        ],\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    hydrosphere_address,\n",
    "    learning_rate,\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    model_name,\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "\n",
    "    train = train_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"], \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        models_path=train.outputs[\"model_path\"],\n",
    "        accuracy=train.outputs[\"accuracy\"],\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace compiled hardcoded namespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name infallible_shockley\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://df3b0da4.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/7a6095db-70c6-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"model_name\": \"mnist\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Deploy to Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we are deploying the model to the stage application to run integration tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_to_stage_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"deploy_to_stage\",\n",
    "        image=f\"{username}/mnist-pipeline-deploy-to-stage:{version}\",\n",
    "        arguments=[\n",
    "            \"--model-version\", kwargs[\"model_version\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"],\n",
    "        ],\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    hydrosphere_address,\n",
    "    learning_rate,\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    model_name,\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "\n",
    "    train = train_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"], \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        models_path=train.outputs[\"model_path\"],\n",
    "        accuracy=train.outputs[\"accuracy\"],\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)\n",
    "    \n",
    "    deploy_to_stage = deploy_to_stage_op(\n",
    "        model_version=release.outputs[\"model_version\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_name=model_name)\n",
    "    deploy_to_stage.after(release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace compiled hardcoded namespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name unruffled_torvalds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://df3b0da4.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/2d6ba56f-70c7-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"model_name\": \"mnist\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we are performing integration tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"test\",\n",
    "        image=f\"{username}/mnist-pipeline-test:{version}\", \n",
    "        arguments=[\n",
    "            \"--data-path\", kwargs[\"data_path\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--acceptable-accuracy\", kwargs[\"acceptable_accuracy\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"], \n",
    "        ],\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    hydrosphere_address,\n",
    "    learning_rate,\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    model_name,\n",
    "    acceptable_accuracy\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "\n",
    "    train = train_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"], \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        models_path=train.outputs[\"model_path\"],\n",
    "        accuracy=train.outputs[\"accuracy\"],\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)\n",
    "    \n",
    "    deploy_to_stage = deploy_to_stage_op(\n",
    "        model_version=release.outputs[\"model_version\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_name=model_name)\n",
    "    deploy_to_stage.after(release)\n",
    "    \n",
    "    test = test_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        acceptable_accuracy=acceptable_accuracy,\n",
    "        model_name=model_name)\n",
    "    test.set_retry(3)\n",
    "    test.after(deploy_to_stage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace compiled hardcoded namespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name blissful_mclean\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://df3b0da4.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/f136b046-70c7-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"acceptable-accuracy\": \"0.90\",\n",
    "        \"model_name\": \"mnist\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 Deploy to Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally deploying the model to production application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_to_prod_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"deploy_to_prod\",\n",
    "        image=f\"{username}/mnist-pipeline-deploy-to-prod:{version}\",\n",
    "        arguments=[\n",
    "            \"--model-version\", kwargs[\"model_version\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"]\n",
    "        ],\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    hydrosphere_address,\n",
    "    learning_rate,\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    model_name,\n",
    "    acceptable_accuracy\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "\n",
    "    train = train_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=download.outputs[\"data_path\"], \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        models_path=train.outputs[\"model_path\"],\n",
    "        accuracy=train.outputs[\"accuracy\"],\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)\n",
    "    \n",
    "    deploy_to_stage = deploy_to_stage_op(\n",
    "        model_version=release.outputs[\"model_version\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_name=model_name)\n",
    "    deploy_to_stage.after(release)\n",
    "    \n",
    "    test = test_op(\n",
    "        data_path=download.outputs[\"data_path\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        acceptable_accuracy=acceptable_accuracy,\n",
    "        model_name=model_name)\n",
    "    test.set_retry(3)\n",
    "    test.after(deploy_to_stage)\n",
    "    \n",
    "    deploy_to_prod = deploy_to_prod_op(\n",
    "        model_version=release.outputs[\"model_version\"],\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "    deploy_to_prod.after(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace compiled hardcoded namespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name condescending_varahamihira\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://df3b0da4.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/4946350a-70c8-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"acceptable-accuracy\": \"0.90\",\n",
    "        \"model_name\": \"mnist\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_production_traffic(shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a fully functional pipeline, we would like to automate running this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_op(**kwargs):\n",
    "    return dsl.ContainerOp(\n",
    "        name=\"sample\",\n",
    "        image=f\"{username}/mnist-pipeline-sample:{version}\", \n",
    "        file_outputs={\"data_path\": \"/data_path.txt\"},\n",
    "        arguments=[\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"],\n",
    "        ]\n",
    "    ).apply(use_aws_secret())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    hydrosphere_address,\n",
    "    learning_rate,\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    model_name,\n",
    "    acceptable_accuracy\n",
    "):\n",
    "    \n",
    "    sample = sample_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_name=model_name)\n",
    "    \n",
    "    train = train_op(\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        data_path=sample.outputs[\"data_path\"], \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(sample)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        data_path=sample.outputs[\"data_path\"],\n",
    "        models_path=train.outputs[\"model_path\"],\n",
    "        accuracy=train.outputs[\"accuracy\"],\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)\n",
    "    \n",
    "    deploy_to_stage = deploy_to_stage_op(\n",
    "        model_version=release.outputs[\"model_version\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_name=model_name)\n",
    "    deploy_to_stage.after(release)\n",
    "    \n",
    "    test = test_op(\n",
    "        data_path=sample.outputs[\"data_path\"],\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        acceptable_accuracy=acceptable_accuracy,\n",
    "        model_name=model_name)\n",
    "    test.set_retry(3)\n",
    "    test.after(deploy_to_stage)\n",
    "    \n",
    "    deploy_to_prod = deploy_to_prod_op(\n",
    "        model_version=release.outputs[\"model_version\"],\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "    deploy_to_prod.after(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace compiled hardcoded namespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name sharp_spence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://df3b0da4.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/f7503ba4-70c9-11e9-9fa9-02d13cd50846\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.0005\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"100\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"acceptable-accuracy\": \"0.60\",\n",
    "        \"model_name\": \"mnist\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_production_traffic(shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
