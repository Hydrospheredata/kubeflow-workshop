{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp, os\n",
    "import kfp.dsl as dsl \n",
    "import kfp.compiler as compiler\n",
    "import kubernetes.client.models as k8s\n",
    "import namesgenerator\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMESPACE = os.environ.get(\"NAMESPACE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubeflow_address = f\"http://{NAMESPACE}.kubeflow.odsc.k8s.hydrosphere.io\"\n",
    "hydrosphere_address = f\"http://{NAMESPACE}.serving.odsc.k8s.hydrosphere.io\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticating with existing credentials...\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!docker login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will obtain all training data for our pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build & publish an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  73.55MB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./download.py /src/\n",
      " ---> a3841e6d6547\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in ab76f97760ca\n",
      "Removing intermediate container ab76f97760ca\n",
      " ---> f2dabc0d28be\n",
      "Step 4/4 : ENTRYPOINT [ \"python\", \"download.py\" ]\n",
      " ---> Running in 38eca19a76f8\n",
      "Removing intermediate container 38eca19a76f8\n",
      " ---> 1d6489f5993f\n",
      "Successfully built 1d6489f5993f\n",
      "Successfully tagged tidylobster/mnist-pipeline-download:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-download]\n",
      "df09be6d9ed4: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "93ed1238773c: Waiting\n",
      "eeb5ce6b3db4: Waiting\n",
      "886601877ba4: Waiting\n",
      "0fc100fdc7f9: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "eee35c27cf87: Layer already exists\n",
      "56995c671038: Layer already exists\n",
      "66a75017de07: Layer already exists\n",
      "83c720aa6f39: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "df09be6d9ed4: Pushed\n",
      "latest: digest: sha256:8fe8571b81bea4080ca0d52343621d521b9c3b5799ab32e82e6ec91b81a36792 size: 3041\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-download:latest --no-cache 01_download\n",
    "docker push tidylobster/mnist-pipeline-download:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Kubernetes PVC resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_pvc = k8s.V1PersistentVolumeClaimVolumeSource(claim_name=\"storage\")\n",
    "storage_volume = k8s.V1Volume(name=\"storage\", persistent_volume_claim=storage_pvc)\n",
    "storage_volume_mount = k8s.V1VolumeMount(mount_path=\"{{workflow.parameters.mount-path}}\", name=\"storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"tidylobster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_op(**kwargs):\n",
    "    download = dsl.ContainerOp(\n",
    "        name=\"download\",\n",
    "        image=f\"{username}/mnist-pipeline-download:latest\",\n",
    "        file_outputs={\"data_path\": \"/data_path.txt\"},\n",
    "        arguments=[\n",
    "            \"--mount-path\", kwargs[\"mount_path\"]\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    download.add_volume(storage_volume)\n",
    "    download.add_volume_mount(storage_volume_mount)\n",
    "    return download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        mount_path=mount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipelines client\n",
    "client = kfp.Client(kubeflow_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an experiment name\n",
    "experiment_name='MNIST Showreal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get or create an experiment_id\n",
    "try:\n",
    "    experiment_id = client.get_experiment(experiment_name=experiment_name).id\n",
    "except:\n",
    "    experiment_id = client.create_experiment(experiment_name).id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name amazing_leavitt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://a432df31.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/70210556-69cc-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(experiment_id, run_name, \"pipeline.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will create a model & train it on the downloaded data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  57.28MB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./train.py /src/\n",
      " ---> 977d3beb5292\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in 22df3fbcabe5\n",
      "Removing intermediate container 22df3fbcabe5\n",
      " ---> b2e233791247\n",
      "Step 4/4 : ENTRYPOINT [ \"python\", \"train.py\" ]\n",
      " ---> Running in 45c21c8a0e0f\n",
      "Removing intermediate container 45c21c8a0e0f\n",
      " ---> 3e8beead0995\n",
      "Successfully built 3e8beead0995\n",
      "Successfully tagged tidylobster/mnist-pipeline-train:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-train]\n",
      "e5a85da65259: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "886601877ba4: Waiting\n",
      "0fc100fdc7f9: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "93ed1238773c: Waiting\n",
      "eeb5ce6b3db4: Waiting\n",
      "66a75017de07: Layer already exists\n",
      "eee35c27cf87: Layer already exists\n",
      "83c720aa6f39: Layer already exists\n",
      "56995c671038: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "e5a85da65259: Pushed\n",
      "latest: digest: sha256:ca28d3b337f6e64654a5c05edad450a6ceee364ea745af631e6abcf9a0b1d292 size: 3041\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-train:latest --no-cache 02_train/ \n",
    "docker push tidylobster/mnist-pipeline-train:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_op(download, **kwargs):\n",
    "    train = dsl.ContainerOp(\n",
    "        name=\"train\",\n",
    "        image=f\"{username}/mnist-pipeline-train:latest\",\n",
    "        file_outputs={\"accuracy\": \"/accuracy.txt\"},\n",
    "        arguments=[\n",
    "            \"--data-path\", download.outputs[\"data_path\"], \n",
    "            \"--mount-path\", kwargs[\"mount_path\"],\n",
    "            \"--learning-rate\", kwargs[\"learning_rate\"],\n",
    "            \"--epochs\", kwargs[\"epochs\"],\n",
    "            \"--batch-size\", kwargs[\"batch_size\"]\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    train.add_volume(storage_volume)\n",
    "    train.add_volume_mount(storage_volume_mount)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        mount_path=mount_path)\n",
    "    \n",
    "    train = train_op(\n",
    "        download, \n",
    "        mount_path=mount_path, \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name romantic_albattani\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://de61b6c3.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/b76b9be3-6859-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we will release the trained model to the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  5.632kB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./execute.sh /src/\n",
      " ---> 516cd80def8f\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in 6ac0166071a4\n",
      "Removing intermediate container 6ac0166071a4\n",
      " ---> 7ef9caae7756\n",
      "Step 4/4 : ENTRYPOINT [ \"bash\", \"execute.sh\" ]\n",
      " ---> Running in 5eb4c50fb456\n",
      "Removing intermediate container 5eb4c50fb456\n",
      " ---> f468359fbd5d\n",
      "Successfully built f468359fbd5d\n",
      "Successfully tagged tidylobster/mnist-pipeline-release:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-release]\n",
      "09aed34a2dac: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "93ed1238773c: Waiting\n",
      "eeb5ce6b3db4: Waiting\n",
      "886601877ba4: Waiting\n",
      "0fc100fdc7f9: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "56995c671038: Layer already exists\n",
      "eee35c27cf87: Layer already exists\n",
      "66a75017de07: Layer already exists\n",
      "83c720aa6f39: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "09aed34a2dac: Pushed\n",
      "latest: digest: sha256:4d67ffb134787eb1927617dcff9c9f14bfbf5d0a66b3fc9e028164876099cd2d size: 3041\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-release:latest --no-cache 03_release/ \n",
    "docker push tidylobster/mnist-pipeline-release:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_op(download, train, **kwargs):\n",
    "    release = dsl.ContainerOp(\n",
    "        name=\"release\",\n",
    "        image=f\"{username}/mnist-pipeline-release:latest\",\n",
    "        file_outputs={\"model-version\": \"/model-version.txt\"},\n",
    "        arguments=[\n",
    "            \"--data-path\", download.outputs[\"data_path\"],\n",
    "            \"--mount-path\", kwargs[\"mount_path\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"],\n",
    "            \"--accuracy\", train.outputs[\"accuracy\"], \n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--learning-rate\", kwargs[\"learning_rate\"],\n",
    "            \"--epochs\", kwargs[\"epochs\"],\n",
    "            \"--batch-size\", kwargs[\"batch_size\"],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    release.add_volume(storage_volume) \n",
    "    release.add_volume_mount(storage_volume_mount)\n",
    "    return release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\"\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        mount_path=mount_path)\n",
    "    \n",
    "    train = train_op(\n",
    "        download, \n",
    "        mount_path=mount_path, \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        download, \n",
    "        train,\n",
    "        mount_path=mount_path,\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name tender_shaw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://de61b6c3.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/d882208a-6858-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy to Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we are deploying the model to the stage application to run integration tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  4.096kB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./execute.sh /src/\n",
      " ---> 04806b527d82\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in 2631adbd23bc\n",
      "Removing intermediate container 2631adbd23bc\n",
      " ---> 8eea1b517fc3\n",
      "Step 4/4 : ENTRYPOINT [ \"bash\", \"execute.sh\" ]\n",
      " ---> Running in f6bb1bbb765d\n",
      "Removing intermediate container f6bb1bbb765d\n",
      " ---> 01b09d21bd0f\n",
      "Successfully built 01b09d21bd0f\n",
      "Successfully tagged tidylobster/mnist-pipeline-deploy-to-stage:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-deploy-to-stage]\n",
      "3c43921fdea3: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "93ed1238773c: Waiting\n",
      "eeb5ce6b3db4: Waiting\n",
      "886601877ba4: Waiting\n",
      "0fc100fdc7f9: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "eee35c27cf87: Layer already exists\n",
      "83c720aa6f39: Layer already exists\n",
      "56995c671038: Layer already exists\n",
      "66a75017de07: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "3c43921fdea3: Pushed\n",
      "latest: digest: sha256:2f5818a45e5c645c43c4fe12ef86b196cc803374584e3ae08dceaebf7e902992 size: 3040\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-deploy-to-stage:latest --no-cache 04_deploy-to-stage/ \n",
    "docker push tidylobster/mnist-pipeline-deploy-to-stage:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_to_stage_op(release, **kwargs):\n",
    "    deploy_to_stage = dsl.ContainerOp(\n",
    "        name=\"deploy_to_stage\",\n",
    "        image=f\"{username}/mnist-pipeline-deploy-to-stage:latest\",\n",
    "        file_outputs={\"stage-app-name\": \"/stage-app-name.txt\"},\n",
    "        arguments=[\n",
    "            \"--model-version\", release.outputs[\"model-version\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"],\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    return deploy_to_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\",\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        mount_path=mount_path)\n",
    "    \n",
    "    train = train_op(\n",
    "        download, \n",
    "        mount_path=mount_path, \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        download, \n",
    "        train,\n",
    "        mount_path=mount_path,\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)\n",
    "    \n",
    "    deploy_to_stage = deploy_to_stage_op(\n",
    "        release,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_name=model_name)\n",
    "    deploy_to_stage.after(release)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name awesome_austin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://de61b6c3.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/ebd7ee7a-6859-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we are performing integration tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  32.07MB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./test.py /src/\n",
      " ---> 26fb5e733c11\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in 817bac0d7a6b\n",
      "Removing intermediate container 817bac0d7a6b\n",
      " ---> 7492898ebf96\n",
      "Step 4/4 : ENTRYPOINT [ \"python\", \"test.py\" ]\n",
      " ---> Running in 778df15f5b79\n",
      "Removing intermediate container 778df15f5b79\n",
      " ---> 43fb53a3dd24\n",
      "Successfully built 43fb53a3dd24\n",
      "Successfully tagged tidylobster/mnist-pipeline-test:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-test]\n",
      "1926742676af: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "0fc100fdc7f9: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "93ed1238773c: Waiting\n",
      "eeb5ce6b3db4: Waiting\n",
      "886601877ba4: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "56995c671038: Layer already exists\n",
      "66a75017de07: Layer already exists\n",
      "eee35c27cf87: Layer already exists\n",
      "83c720aa6f39: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "1926742676af: Pushed\n",
      "latest: digest: sha256:e991d42d8cfe21986f6212c29be019f59cc75d1fd3930e2403a52ea6bd6a52fa size: 3040\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-test:latest --no-cache 05_test/ \n",
    "docker push tidylobster/mnist-pipeline-test:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_op(download, stage, **kwargs):\n",
    "    test = dsl.ContainerOp(\n",
    "        name=\"test\",\n",
    "        image=f\"{username}/mnist-pipeline-test:latest\", \n",
    "        arguments=[\n",
    "            \"--stage-app-name\", stage.outputs[\"stage-app-name\"], \n",
    "            \"--data-path\", download.outputs[\"data_path\"],\n",
    "            \"--mount-path\", kwargs[\"mount_path\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "            \"--acceptable-accuracy\", kwargs[\"acceptable_accuracy\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"], \n",
    "        ],\n",
    "    )\n",
    "\n",
    "    test.add_volume(storage_volume) \n",
    "    test.add_volume_mount(storage_volume_mount)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\",\n",
    "    acceptable_accuracy=\"0.90\",\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        mount_path=mount_path)\n",
    "    \n",
    "    train = train_op(\n",
    "        download, \n",
    "        mount_path=mount_path, \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        download, \n",
    "        train,\n",
    "        mount_path=mount_path,\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)\n",
    "    \n",
    "    deploy_to_stage = deploy_to_stage_op(\n",
    "        release,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_name=model_name)\n",
    "    deploy_to_stage.after(release)\n",
    "    \n",
    "    test = test_op(\n",
    "        download, \n",
    "        deploy_to_stage,\n",
    "        mount_path=mount_path,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        acceptable_accuracy=acceptable_accuracy,\n",
    "        model_name=model_name)\n",
    "    test.set_retry(3)\n",
    "    test.after(deploy_to_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name suspicious_jepsen\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://de61b6c3.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/ba541c37-685a-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"acceptable-accuracy\": \"0.90\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy to Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally deploying the model to production application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  3.584kB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./execute.sh /src/\n",
      " ---> 5b81cae3f71e\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in 57ea748b77a2\n",
      "Removing intermediate container 57ea748b77a2\n",
      " ---> 79bf11a3862f\n",
      "Step 4/4 : ENTRYPOINT [ \"bash\", \"execute.sh\" ]\n",
      " ---> Running in 1b17f9ff44c4\n",
      "Removing intermediate container 1b17f9ff44c4\n",
      " ---> 4de1f85b1b33\n",
      "Successfully built 4de1f85b1b33\n",
      "Successfully tagged tidylobster/mnist-pipeline-deploy-to-prod:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-deploy-to-prod]\n",
      "5866111ec03b: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "93ed1238773c: Waiting\n",
      "eeb5ce6b3db4: Waiting\n",
      "0fc100fdc7f9: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "886601877ba4: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "eee35c27cf87: Layer already exists\n",
      "56995c671038: Layer already exists\n",
      "66a75017de07: Layer already exists\n",
      "83c720aa6f39: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "5866111ec03b: Pushed\n",
      "latest: digest: sha256:f728013f3ee268418e87216f43428b47ab6e0b535e1460fa31d070d5a51bd083 size: 3040\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-deploy-to-prod:latest --no-cache 06_deploy-to-prod/ \n",
    "docker push tidylobster/mnist-pipeline-deploy-to-prod:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_to_prod_op(release, **kwargs):\n",
    "    deploy_to_prod = dsl.ContainerOp(\n",
    "        name=\"deploy_to_prod\",\n",
    "        image=f\"{username}/mnist-pipeline-deploy-to-prod:latest\",   # <-- Replace with correct docker image\n",
    "        arguments=[\n",
    "            \"--model-version\", release.outputs[\"model-version\"],\n",
    "            \"--model-name\", kwargs[\"model_name\"],\n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"]\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return deploy_to_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\",\n",
    "    acceptable_accuracy=\"0.90\",\n",
    "):\n",
    "    \n",
    "    download = download_op(\n",
    "        mount_path=mount_path)\n",
    "    \n",
    "    train = train_op(\n",
    "        download, \n",
    "        mount_path=mount_path, \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(download)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        download, \n",
    "        train,\n",
    "        mount_path=mount_path,\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)\n",
    "    \n",
    "    deploy_to_stage = deploy_to_stage_op(\n",
    "        release,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_name=model_name)\n",
    "    deploy_to_stage.after(release)\n",
    "    \n",
    "    test = test_op(\n",
    "        download, \n",
    "        deploy_to_stage,\n",
    "        mount_path=mount_path,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        acceptable_accuracy=acceptable_accuracy,\n",
    "        model_name=model_name)\n",
    "    test.set_retry(3)\n",
    "    test.after(deploy_to_stage)\n",
    "    \n",
    "    deploy_to_prod = deploy_to_prod_op(\n",
    "        release,\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "    deploy_to_prod.after(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i \"s/minio-service.kubeflow/minio-service.${NAMESPACE}/g\" pipeline.yaml\n",
    "sed -i \"s/pipeline-runner/${NAMESPACE}-pipeline-runner/g\" pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name quizzical_dubinsky\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://de61b6c3.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/054275d1-6862-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"acceptable-accuracy\": \"0.90\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_production_traffic(request_delay=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a fully functional pipeline, we would like to automate running this pipeline. But we don't "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and publish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  145.4kB\r",
      "\r\n",
      "Step 1/4 : FROM tidylobster/odsc-base:1.0\n",
      " ---> a44d37e5b862\n",
      "Step 2/4 : ADD ./sample.py /src/\n",
      " ---> d0bf9fa1e60f\n",
      "Step 3/4 : WORKDIR /src/\n",
      " ---> Running in 74cf2db395d9\n",
      "Removing intermediate container 74cf2db395d9\n",
      " ---> d897843f8920\n",
      "Step 4/4 : ENTRYPOINT [ \"python\", \"sample.py\" ]\n",
      " ---> Running in 600c6e2c5138\n",
      "Removing intermediate container 600c6e2c5138\n",
      " ---> b8eab9e6ea5b\n",
      "Successfully built b8eab9e6ea5b\n",
      "Successfully tagged tidylobster/mnist-pipeline-sample:latest\n",
      "The push refers to repository [docker.io/tidylobster/mnist-pipeline-sample]\n",
      "0d3f17e845d9: Preparing\n",
      "66a75017de07: Preparing\n",
      "83c720aa6f39: Preparing\n",
      "56995c671038: Preparing\n",
      "eee35c27cf87: Preparing\n",
      "93ed1238773c: Preparing\n",
      "eeb5ce6b3db4: Preparing\n",
      "886601877ba4: Preparing\n",
      "0fc100fdc7f9: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "0fc100fdc7f9: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "93ed1238773c: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "eeb5ce6b3db4: Waiting\n",
      "886601877ba4: Waiting\n",
      "83c720aa6f39: Layer already exists\n",
      "66a75017de07: Layer already exists\n",
      "eee35c27cf87: Layer already exists\n",
      "56995c671038: Layer already exists\n",
      "93ed1238773c: Layer already exists\n",
      "886601877ba4: Layer already exists\n",
      "eeb5ce6b3db4: Layer already exists\n",
      "0fc100fdc7f9: Layer already exists\n",
      "0de2edf7bff4: Layer already exists\n",
      "b2fd8b4c3da7: Layer already exists\n",
      "68dda0c9a8cd: Layer already exists\n",
      "f67191ae09b8: Layer already exists\n",
      "0d3f17e845d9: Pushed\n",
      "latest: digest: sha256:df3dd493238f35d688bf7c1ab4f6bf6d6ad3e3a536cf1cfe1f9842dc61ad2510 size: 3041\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "docker build -t tidylobster/mnist-pipeline-sample:latest --no-cache 01_sample/ \n",
    "docker push tidylobster/mnist-pipeline-sample:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define container operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_op(**kwargs):\n",
    "    sample = dsl.ContainerOp(\n",
    "        name=\"sample\",\n",
    "        image=f\"{username}/mnist-pipeline-sample:latest\", # <-- Replace with correct docker image\n",
    "        file_outputs={\"data_path\": \"/data_path.txt\"},\n",
    "        arguments=[\n",
    "            \"--mount-path\", kwargs[\"mount_path\"], \n",
    "            \"--hydrosphere-address\", kwargs[\"hydrosphere_address\"],\n",
    "        ]\n",
    "    )  \n",
    "    \n",
    "    sample.add_volume(storage_volume)\n",
    "    sample.add_volume_mount(storage_volume_mount)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"mnist\", description=\"MNIST classifier\")\n",
    "def pipeline_definition(\n",
    "    mount_path=\"/storage\",\n",
    "    learning_rate=\"0.01\",\n",
    "    epochs=\"10\",\n",
    "    batch_size=\"256\",\n",
    "    model_name=\"mnist\",\n",
    "    hydrosphere_address=\"\",\n",
    "    acceptable_accuracy=\"0.90\",\n",
    "):\n",
    "    \n",
    "    sample = sample_op(\n",
    "        mount_path=mount_path, \n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "    \n",
    "    train = train_op(\n",
    "        sample, \n",
    "        mount_path=mount_path, \n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    train.after(sample)\n",
    "    train.set_memory_request('1G')\n",
    "    train.set_cpu_request('1')\n",
    "    \n",
    "    release = release_op(\n",
    "        sample, \n",
    "        train,\n",
    "        mount_path=mount_path, \n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "    release.after(train)\n",
    "    \n",
    "    deploy_to_stage = deploy_to_stage_op(\n",
    "        release,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        model_name=model_name)\n",
    "    deploy_to_stage.after(release)\n",
    "    \n",
    "    test = test_op(\n",
    "        sample, \n",
    "        deploy_to_stage,\n",
    "        mount_path=mount_path,\n",
    "        hydrosphere_address=hydrosphere_address,\n",
    "        acceptable_accuracy=acceptable_accuracy,\n",
    "        model_name=model_name)\n",
    "    test.set_retry(3)\n",
    "    test.after(deploy_to_stage)\n",
    "    \n",
    "    deploy_to_prod = deploy_to_prod_op(\n",
    "        release,\n",
    "        model_name=model_name,\n",
    "        hydrosphere_address=hydrosphere_address)\n",
    "    deploy_to_prod.after(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_definition, \"pipeline.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x pipeline.yaml\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "tar -xvf pipeline.tar.gz\n",
    "sed -i '' s/minio-service.kubeflow/minio-service.${NAMESPACE}/g pipeline.yaml\n",
    "sed -i '' s/pipeline-runner/${NAMESPACE}-pipeline-runner/g pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new run with the name serene_perlman\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"http://de61b6c3.kubeflow.odsc.k8s.hydrosphere.io/#/runs/details/fac71d17-6863-11e9-a794-02ee3ec3938a\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start a run\n",
    "run_name = namesgenerator.get_random_name()\n",
    "print(\"Starting a new run with the name {}\".format(run_name))\n",
    "result = client.run_pipeline(\n",
    "    experiment_id, run_name, \"pipeline.yaml\",\n",
    "    {\n",
    "        \"learning-rate\": \"0.01\",\n",
    "        \"batch-size\": \"256\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"hydrosphere-address\": hydrosphere_address,\n",
    "        \"acceptable-accuracy\": \"0.30\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
